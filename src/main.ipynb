{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from struct import *\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from pyswarm import pso\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib notebook\n",
    "plt.rcParams['figure.figsize'] = (8, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2pol(x, y):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return (rho, phi)\n",
    "\n",
    "def pol2cart(rho, phi):\n",
    "    x = rho * np.cos(phi)\n",
    "    y = rho * np.sin(phi)\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_codes(x, y, numbers, name):\n",
    "    %matplotlib inline\n",
    "    plt.rcParams['figure.figsize'] = (12, 12)\n",
    "    plt.scatter(x, y, color=color_map[numbers])\n",
    "    for i in range(10):\n",
    "        index = np.argmax(numbers == i)\n",
    "        x_pos = x[index]\n",
    "        y_pos = y[index]\n",
    "        plt.scatter(x_pos, y_pos, color=color_map[i], label=i)\n",
    "    legend = plt.legend()\n",
    "    plt.savefig(name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(result, reference, shape, i):\n",
    "    result = np.reshape(result, shape)\n",
    "    reference = np.reshape(reference, shape)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(reference, cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(result, cmap='gray')\n",
    "    plt.savefig(str(i)+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_error(fig, ax, data_x, data_y):\n",
    "    if ax[0].lines:\n",
    "        for i in range(len(ax[0].lines)):\n",
    "            ax[0].lines[i].set_xdata(data_x[-50:])\n",
    "            ax[0].lines[i].set_ydata(data_y[i][-50:])\n",
    "        ax[0].set_xlim(min(data_x[-50:]), max(data_x[-50:]))\n",
    "        ax[0].set_ylim(0.9*np.min([data[-50:] for data in data_y]),\n",
    "                       1.1*np.max([data[-50:] for data in data_y]))\n",
    "    else:\n",
    "        for line in data_y:\n",
    "            ax[0].plot(data_x, line)\n",
    "    if ax[1].lines:\n",
    "        for i in range(len(ax[1].lines)):\n",
    "            ax[1].lines[i].set_xdata(data_x[1:])\n",
    "            ax[1].lines[i].set_ydata(data_y[i][1:])\n",
    "        ax[1].set_xlim(data_x[1], data_x[-1])\n",
    "        ax[1].set_ylim(0, np.max([data[1:] for data in data_y]))\n",
    "    else:\n",
    "        for line in data_y:\n",
    "            ax[1].plot(data_x, line)\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(layers, iterator):\n",
    "    true_count = min(15, layers[iterator])\n",
    "    false_count = max(0, layers[iterator] - true_count)  \n",
    "    return tf.Variable(\n",
    "            [\n",
    "            tf.random_shuffle(\n",
    "                [True for _ in range(true_count)] + [False for _ in range(false_count)]\n",
    "            ) for i in range(layers[iterator + 1])\n",
    "        ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_value(layers, iterator):\n",
    "    true_count = min(15, layers[iterator])\n",
    "    false_count = max(0, layers[iterator] - true_count)  \n",
    "    \n",
    "    value = [np.random.permutation(np.concatenate([np.random.normal(0, 1, true_count), [0]*false_count])).tolist() for _ in range(layers[iterator + 1])]\n",
    "\n",
    "    return  np.array(value).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(x, a = 1.6733, l = 1.0507):\n",
    "    pos = l * tf.nn.relu(x)\n",
    "    neg = l * (a * tf.exp( (x - tf.abs(x)) * 0.5 ) - a)\n",
    "    return pos + neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder_model(layers, x, activation, last_layer = 'linear'):\n",
    "    size = (len(layers) - 1 ) * 2\n",
    "    W = [None for _ in range(size)]\n",
    "    y = [None for _ in range(size)]\n",
    "    mask = [None for _ in range(size)]\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    batch_tiled = tf.fill([batch_size, 1], 1.0)\n",
    "        \n",
    "    for iterator in range(len(layers) - 1): \n",
    "        if (activation == tf.nn.sigmoid):\n",
    "            W[iterator] = tf.Variable(\n",
    "                tf.concat([np.transpose(generate_initial_value(layers, iterator)), tf.zeros([1, layers[iterator + 1]])], 0), name= \"W\" + str(iterator)\n",
    "            )\n",
    "        elif (activation == selu):            \n",
    "            W[iterator] = tf.Variable(\n",
    "                tf.concat([\n",
    "                    tf.truncated_normal([layers[iterator], layers[iterator + 1]], 0, 1/np.sqrt(layers[iterator])),\n",
    "                    tf.zeros([1, layers[iterator + 1]])\n",
    "                ], 0),\n",
    "                name= \"W\" + str(iterator)\n",
    "            )\n",
    "        if iterator == 0:\n",
    "            y[iterator] = activation(tf.matmul(tf.concat([x, batch_tiled], 1), W[iterator]))\n",
    "        elif iterator == len(layers) - 2:\n",
    "            y[iterator] = tf.matmul(tf.concat([y[iterator-1], batch_tiled], 1), W[iterator])\n",
    "        else:\n",
    "            y[iterator] = activation(tf.matmul(tf.concat([y[iterator-1], batch_tiled], 1), W[iterator]))\n",
    "        \n",
    "    for iterator in range(len(layers) - 1):\n",
    "        if (activation == tf.nn.sigmoid):\n",
    "            W[iterator + len(layers) - 1] = tf.Variable(\n",
    "                tf.concat([\n",
    "                    generate_initial_value(layers, len(layers) - 2 - iterator),\n",
    "                    tf.zeros([1, layers[len(layers) - iterator - 2]])\n",
    "                ], 0),    \n",
    "                name= \"W\" + str(iterator + len(layers) - 1)\n",
    "            )\n",
    " \n",
    "        elif (activation == selu):\n",
    "            W[iterator + len(layers) - 1] = tf.Variable(\n",
    "                tf.concat([\n",
    "                    tf.truncated_normal(\n",
    "                        [layers[len(layers) - iterator - 1],\n",
    "                         layers[len(layers) - iterator - 2]],\n",
    "                        0, \n",
    "                        1/np.sqrt(layers[len(layers) - iterator - 1])),\n",
    "                    tf.zeros([1, layers[len(layers) - iterator - 2]])\n",
    "                ], 0),\n",
    "                name= \"W\" + str(iterator + len(layers) - 1)\n",
    "            )\n",
    "        y[iterator + len(layers) - 1] = activation(tf.matmul(tf.concat([y[iterator + len(layers) - 2], batch_tiled], 1) , W[iterator + len(layers) - 1]))\n",
    "    \n",
    "    if(last_layer == 'linear'):\n",
    "        y[size - 1] = tf.matmul(tf.concat([y[size - 2], batch_tiled], 1), W[size - 1])\n",
    "    elif(last_layer == 'sigmoid'):\n",
    "        y[size - 1] = tf.nn.sigmoid(tf.matmul(tf.concat([y[size - 2], batch_tiled], 1), W[size - 1]))\n",
    "    elif(last_layer == 'selu'):\n",
    "        y[size - 1] = selu(tf.matmul(tf.concat([y[size - 2], batch_tiled], 1), W[size - 1]))\n",
    "    elif(last_layer == 'activation'):\n",
    "        y[size - 1] = activation(tf.matmul(tf.concat([y[size - 2], batch_tiled], 1), W[size - 1]))\n",
    "    else:\n",
    "        y[size - 1] = activation(tf.matmul(tf.concat([y[size - 2], batch_tiled], 1), W[size - 1]))\n",
    "    \n",
    "    return W, y[-1], y[len(layers) - 2], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    input_size = 0\n",
    "    output_size = 0\n",
    "    samples_count = 0\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    double_size = 8\n",
    "    min_value = 0\n",
    "    max_value = 0\n",
    "\n",
    "    def __init__(self, file_path, zero_one):\n",
    "        self.read_data_bin(file_path, zero_one)\n",
    "        \n",
    "    def scale_to_zero_one(self, data):\n",
    "        data = (data - self.min_value)/(self.max_value-self.min_value)\n",
    "        return data\n",
    "    \n",
    "    def scale_to_original(self, data):\n",
    "        return data*(self.max_value-self.min_value) + self.min_value\n",
    "    \n",
    "    def read_data_bin(self,file_path, zero_one):\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        file = open(file_path, \"rb\")\n",
    "        self.samples_count, self.input_size, self.output_size = unpack(\"iii\", file.read(12))\n",
    "                \n",
    "        for i in tnrange(self.samples_count):\n",
    "            self.inputs.append(unpack(str(self.input_size)+\"d\", file.read(self.double_size * self.input_size)))\n",
    "            self.outputs.append(unpack(str(self.output_size)+\"d\", file.read(self.double_size * self.output_size)))\n",
    "\n",
    "        self.inputs = np.array(self.inputs)\n",
    "        self.outputs = np.array(self.outputs)\n",
    "\n",
    "        self.min_value = self.inputs.min()        \n",
    "        self.max_value = self.inputs.max()\n",
    "        if(zero_one):\n",
    "            self.inputs = self.scale_to_zero_one(self.inputs)\n",
    "        \n",
    "        file.close()\n",
    "    \n",
    "    def get_next_bach(self, count):\n",
    "        indexes = random.sample(range(self.samples_count), count)\n",
    "        return [self.inputs[indexes], self.outputs[indexes]]\n",
    "    \n",
    "    def get_full_data(self):\n",
    "        return [self.inputs, self.outputs]                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_set = DataSet(\"C:\\Mgr\\DataSets\\HandwrittenDigitsMnist.bin\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "activation = selu\n",
    "\n",
    "input_dim = 784\n",
    "autoencoder_layers = [784, 1000, 500, 250, 2]\n",
    "\n",
    "shape = (28, 28)\n",
    "last_layer = 'sigmoid'\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, input_dim], name = 'x')\n",
    "\n",
    "W, y, code_layer, layers_y = create_autoencoder_model(autoencoder_layers, x, activation, last_layer)\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, input_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_avg_sqr = tf.reduce_mean(tf.reduce_sum(tf.square(y_ - y), axis=1))\n",
    "error_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y) + (1 - y_) * tf.log(1-y), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_xs, batch_ys = data_set.get_next_bach(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moment = tf.placeholder(tf.float32, shape=[])\n",
    "eps = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "grad_norms = [tf.Variable(1.0) for _ in range((len(autoencoder_layers)-1)*2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opimalizer = tf.train.MomentumOptimizer(eps, moment, use_nesterov = False)\n",
    "gradients = opimalizer.compute_gradients(error_entropy)\n",
    "iteration = tf.placeholder(tf.float32, shape=[], name = 'iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = opimalizer.apply_gradients(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "time2 = time.time()\n",
    "\n",
    "print((time2-time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "batch_size = 200 \n",
    "print_info_rate = 10000      \n",
    "iteration_count = 1_000_000    \n",
    "max_moment = 0.99\n",
    "\n",
    "eps_param = 0.0001\n",
    "\n",
    "range_moment = 50_000\n",
    "\n",
    "fig, ax = plt.subplots(2,1)\n",
    "\n",
    "iterations = []\n",
    "errors = []\n",
    "mean_errors = []\n",
    "mean_train_error_avg_sqr = 0\n",
    "error_alpha = 0.2\n",
    "\n",
    "grad_norms_agregated = [[] for _ in range(len(grad_norms))]\n",
    "\n",
    "for i in tnrange(0, iteration_count+1, batch_size, desc='Learning'):\n",
    "    batch_xs, batch_ys = data_set.get_next_bach(batch_size)\n",
    "    momentum = 1 - max(1 - max_moment, 0.5 / (i//range_moment + 1))\n",
    "    sess.run([train_step], feed_dict={x: batch_xs, y_: batch_xs, moment: momentum, eps: eps_param, iteration: int(i/batch_size)})\n",
    "\n",
    "    if i % print_info_rate == 0:\n",
    "        train_error_entropy = error_entropy.eval(feed_dict={\n",
    "          x: batch_xs, y_: batch_xs})\n",
    "        train_error_avg_sqr = error_avg_sqr.eval(feed_dict={\n",
    "          x: batch_xs, y_: batch_xs})\n",
    "        \n",
    "        mean_train_error_avg_sqr = mean_train_error_avg_sqr * (1-error_alpha) + train_error_avg_sqr * error_alpha\n",
    "        iterations.append(i)\n",
    "        errors.append(train_error_avg_sqr)\n",
    "        mean_errors.append(mean_train_error_avg_sqr)\n",
    "        plt_error(fig, ax[:2], iterations, [errors, mean_errors])\n",
    "        print('%d\\t %.4f\\t %.4f\\t %.4f\\t %.4f\\t %f' % (i, train_error_entropy, train_error_avg_sqr, mean_train_error_avg_sqr, eps_param, momentum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "\n",
    "test, labels = data_set.get_next_bach(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sess.run(y, feed_dict={x: test, y_: test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for i in tnrange(0,100, desc='Pictures'):\n",
    "    plt.figure()\n",
    "    compare_results(result[i], test[i], shape, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = list(matplotlib.cm.tab10.colors)\n",
    "color_map = np.array(color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numbers = np.argmax(labels, axis=1)\n",
    "codes = sess.run(code_layer, feed_dict={x: test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_scale = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module, theta = cart2pol(codes[:,0], codes[:,1])\n",
    "module = module**alpha_scale\n",
    "plot_codes(module, theta, numbers, 'radial2D_'+str(alpha_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module, theta = cart2pol(codes[:,0], codes[:,1])\n",
    "module = module**alpha_scale\n",
    "x_code, y_code = pol2cart(module, theta)\n",
    "plot_codes(x_code, y_code, numbers, 'normal2D_'+str(alpha_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
